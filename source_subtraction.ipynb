{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a7941d-eced-4116-86ae-856f746191a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from scipy.ndimage import label, maximum_position, distance_transform_edt\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea263bf-2f21-4776-b3dd-46fa4d3654c9",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1180d9e3-601a-4b45-9553-48ed886a2d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to filter through potential sources and assess whether the candidate is a local maximum and has a sufficient radial profile\n",
    "\n",
    "def is_star_candidate(image, x, y, X_full, Y_full, box_size=7, inner_radius=3, outer_radius=7, min_contrast=2.0):\n",
    "\n",
    "    x_int = int(round(x))\n",
    "    y_int = int(round(y))\n",
    "    \n",
    "    half_box = box_size // 2\n",
    "    y_min = max(0, y_int - half_box)\n",
    "    y_max = min(image.shape[0], y_int + half_box + 1)\n",
    "    x_min = max(0, x_int - half_box)\n",
    "    x_max = min(image.shape[1], x_int + half_box + 1)\n",
    "    sub_box = image[y_min:y_max, x_min:x_max]\n",
    "    if np.nanmax(sub_box) != image[y_int, x_int]:\n",
    "        return False\n",
    "\n",
    "    local_y_min = max(0, y_int - outer_radius)\n",
    "    local_y_max = min(image.shape[0], y_int + outer_radius + 1)\n",
    "    local_x_min = max(0, x_int - outer_radius)\n",
    "    local_x_max = min(image.shape[1], x_int + outer_radius + 1)\n",
    "    Y_local = Y_full[local_y_min:local_y_max, local_x_min:local_x_max]\n",
    "    X_local = X_full[local_y_min:local_y_max, local_x_min:local_x_max]\n",
    "    \n",
    "    r = np.sqrt((X_local - x_int)**2 + (Y_local - y_int)**2)\n",
    "    annulus_mask = (r >= inner_radius) & (r < outer_radius)\n",
    "    if np.sum(annulus_mask) < 2:\n",
    "        return False\n",
    "    annulus_median = np.nanmedian(image[local_y_min:local_y_max, local_x_min:local_x_max][annulus_mask])\n",
    "    annulus_std = np.nanstd(image[local_y_min:local_y_max, local_x_min:local_x_max][annulus_mask])\n",
    "    \n",
    "    return image[y_int, x_int] > annulus_median + min_contrast * annulus_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e6ef6a-13e7-4172-af1f-2898ac175549",
   "metadata": {},
   "source": [
    "## Main Source Subtraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34faf5a3-15ab-41d4-83b5-eb65be924ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psf_subtraction_cycle(detection_image, working_image, cycle_label, psf_data, output_dir,\n",
    "                          mosaic_header, permanent_mask, mask_distance, min_mask_sep=3,\n",
    "                          catalog_filename=None, threshold_sigma=3.0):\n",
    "\n",
    "    print(f\"\\n--- Starting Cycle {cycle_label} ---\")\n",
    "    \n",
    "    # Calculate Background Statistics\n",
    "    _, global_median, global_std = sigma_clipped_stats(detection_image, sigma=3.0)\n",
    "    threshold = global_median + threshold_sigma * global_std\n",
    "    print(f\"Cycle {cycle_label}: Global median = {global_median:.3f}, std = {global_std:.3f}, threshold = {threshold:.3f}\")\n",
    "    \n",
    "    # Identify Potential Sources and Positions\n",
    "    bmask = detection_image > threshold\n",
    "    labeled, num_regions = label(bmask)\n",
    "    print(f\"Cycle {cycle_label}: Number of connected regions above threshold: {num_regions}\")\n",
    "    \n",
    "    initial_positions = maximum_position(detection_image, labels=labeled,\n",
    "                                          index=np.arange(1, num_regions+1))\n",
    "\n",
    "    # Filter Potential Sources and Create Final Source List\n",
    "    source_list = []\n",
    "    Y_full, X_full = np.indices(detection_image.shape)\n",
    "    for pos in initial_positions:\n",
    "        y, x = pos\n",
    "        \n",
    "        if mask_distance[y, x] < min_mask_sep:\n",
    "            continue\n",
    "            \n",
    "        brightness = detection_image[y, x]\n",
    "        if np.isnan(brightness):\n",
    "            continue\n",
    "            \n",
    "        if is_star_candidate(detection_image, x, y, X_full, Y_full, box_size=1, inner_radius=1, outer_radius=2, min_contrast=0.5):\n",
    "            source_list.append((x, y, brightness))\n",
    "\n",
    "    # Sort Final List by Decreasing Brightness\n",
    "    source_list = sorted(source_list, key=lambda s: s[2], reverse=True)\n",
    "    \n",
    "    print(f\"Cycle {cycle_label}: {len(source_list)} candidate sources passed.\")\n",
    "\n",
    "    # Initialize List to Keep Track of Subtracted Sources\n",
    "    new_subtracted_sources = []\n",
    "    \n",
    "    # Define Magnitude Zero-Point\n",
    "    mag_zeropoint = 20.787  # Set by user based on mosaic in use\n",
    "\n",
    "    # Establish Header for Catalog - can be set by user\n",
    "    if catalog_filename is not None and not os.path.exists(catalog_filename):\n",
    "        with open(catalog_filename, \"w\") as f:\n",
    "            f.write(\"# Cycle  SourceIndex   X(pix)   Y(pix)   PeakDN   ScalingFactor   ABmag\\n\")\n",
    "            f.write(\"# -----------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    # Iterate Over Each Source\n",
    "    for i, (x, y, bright) in enumerate(source_list, start=1):\n",
    "        \n",
    "        psf_shape = psf_data.shape\n",
    "        half_psf_x = psf_shape[1] // 2\n",
    "        half_psf_y = psf_shape[0] // 2\n",
    "        x_int, y_int = int(round(x)), int(round(y))\n",
    "        xmin = max(0, x_int - half_psf_x)\n",
    "        xmax = min(working_image.shape[1], x_int + half_psf_x)\n",
    "        ymin = max(0, y_int - half_psf_y)\n",
    "        ymax = min(working_image.shape[0], y_int + half_psf_y)\n",
    "        \n",
    "        # Extract Region Corresponding to PSF Model\n",
    "        region = working_image[ymin:ymax, xmin:xmax]\n",
    "        psf_resized = psf_data[:region.shape[0], :region.shape[1]]\n",
    "        \n",
    "        # Calculate PSF Scaling Factor\n",
    "        s = np.nansum(region * psf_resized) / np.nansum(psf_resized**2)\n",
    "        \n",
    "        # Compute AB Magnitude \n",
    "        if bright > 0:\n",
    "            peak_mag = -2.5 * np.log10(s) + mag_zeropoint\n",
    "        else:\n",
    "            # Dummy value to save if brightness is not a positive value\n",
    "            peak_mag = 99.999\n",
    "        \n",
    "        # Save Statistics to Catalog\n",
    "        if catalog_filename is not None:\n",
    "            with open(catalog_filename, \"a\") as f:\n",
    "                f.write(f\"{cycle_label:<5d} {i:<12d} {x:9.1f} {y:8.1f} {bright:9.2f} {s:14.3f} {peak_mag:9.3f}\\n\")\n",
    "        \n",
    "        # PSF Subtraction\n",
    "        working_image[ymin:ymax, xmin:xmax] -= s * psf_resized\n",
    "\n",
    "        # Save Subtracted Source to List\n",
    "        new_subtracted_sources.append((x, y))\n",
    "    \n",
    "    # Save Updated Residual Image After Each Iteration\n",
    "    out_file = os.path.join(output_dir, f'final_psf_subtracted_cycle{cycle_label}.fits')\n",
    "    final_display = np.nan_to_num(working_image, nan=0)\n",
    "    fits.PrimaryHDU(final_display, header=mosaic_header).writeto(out_file, overwrite=True)\n",
    "    print(f\"Cycle {cycle_label}: Saved PSF-subtracted image as {out_file}\")\n",
    "    \n",
    "    # Write Total Number of Sources Subtracted in this Cycle to Catalog\n",
    "    if catalog_filename is not None:\n",
    "        with open(catalog_filename, \"a\") as f:\n",
    "            f.write(f\"# Cycle {cycle_label}: {len(new_subtracted_sources)} sources subtracted\\n\")\n",
    "    \n",
    "    return working_image, new_subtracted_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cb8261-e591-4ed2-830b-29124d66896a",
   "metadata": {},
   "source": [
    "## Main Iterative Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778fb5b5-28f3-47e2-8cff-06e53513a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to be Set by User\n",
    "mosaic_file = 'mosaic_file'\n",
    "psf_file = 'psf_file'\n",
    "output_dir = 'output_directory'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Establish Catalog\n",
    "catalog_filename = os.path.join(output_dir, \"source_catalog.tex\")\n",
    "\n",
    "# Load Data\n",
    "with fits.open(mosaic_file) as hdu:\n",
    "    data = np.copy(hdu[0].data)\n",
    "    mosaic_header = hdu[0].header\n",
    "\n",
    "with fits.open(psf_file) as hdu_psf:\n",
    "    psf_data = np.copy(hdu_psf[0].data)\n",
    "\n",
    "# Print Mosaic Dimensions\n",
    "ny, nx = data.shape\n",
    "print(f\"Mosaic dimensions: {nx} x {ny} pixels\")\n",
    "\n",
    "# Set 'mosaic' Variable\n",
    "mosaic = data\n",
    "\n",
    "### Routine to Mask Out Saturated Pixels\n",
    "\n",
    "saturation_threshold = 60.0              # saturation threshold; to be adjusted by user\n",
    "small_initial_mask_radius = 160          # small mask radius; to be adjusted by user  \n",
    "large_initial_mask_radius = 220          # large mask radius; to be adjusted by user \n",
    "   \n",
    "# Define Global Background\n",
    "global_bg = np.nanmedian(mosaic)\n",
    "\n",
    "# Identify Saturated Regions\n",
    "saturated_pixels = mosaic > saturation_threshold\n",
    "labeled_saturated, num_sat = label(saturated_pixels)\n",
    "print(f\"Number of saturated regions detected: {num_sat}\")\n",
    "\n",
    "# Iterate Through Saturated Regions and Collect Statistics\n",
    "region_info = []\n",
    "for region_label in range(1, num_sat+1):\n",
    "    y_indices, x_indices = np.where(labeled_saturated == region_label)\n",
    "    if len(y_indices) == 0:\n",
    "        continue\n",
    "    region_values = mosaic[y_indices, x_indices]\n",
    "    peak_index = np.argmax(region_values)\n",
    "    y_peak, x_peak = y_indices[peak_index], x_indices[peak_index]\n",
    "    \n",
    "    distances_region = np.sqrt((x_indices - x_peak)**2 + (y_indices - y_peak)**2)\n",
    "    effective_radius = np.max(distances_region)\n",
    "    \n",
    "    x_min_box, x_max_box = np.min(x_indices), np.max(x_indices)\n",
    "    y_min_box, y_max_box = np.min(y_indices), np.max(y_indices)\n",
    "    width = x_max_box - x_min_box + 1\n",
    "    height = y_max_box - y_min_box + 1\n",
    "    aspect_ratio = width / height if height != 0 else 1.0\n",
    "    peak_flux = np.nanmax(region_values)\n",
    "    \n",
    "    region_info.append((region_label, y_peak, x_peak, effective_radius, aspect_ratio, peak_flux))\n",
    "\n",
    "# Calculate Average Effective Radius of Saturated Regions\n",
    "if region_info:\n",
    "    avg_effective_radius = np.mean([info[3] for info in region_info])\n",
    "else:\n",
    "    avg_effective_radius = 0\n",
    "print(f\"Average effective radius = {avg_effective_radius:.1f} pixels\")\n",
    "\n",
    "# Set Mask Size for Each Region Based on Effective Radius\n",
    "for (region_label, y_peak, x_peak, effective_radius, aspect_ratio, peak_flux) in region_info:\n",
    "    if effective_radius <= avg_effective_radius * 1.5:\n",
    "        r_final = small_initial_mask_radius\n",
    "    else:\n",
    "        r_final = large_initial_mask_radius\n",
    "    Y, X = np.indices(mosaic.shape)\n",
    "    distance_arr = np.sqrt((X - x_peak)**2 + (Y - y_peak)**2)\n",
    "    final_mask = distance_arr <= r_final\n",
    "    mosaic[final_mask] = np.nan\n",
    "\n",
    "permanent_mask = np.isnan(mosaic)\n",
    "\n",
    "# Sets Mask Separation Distance - Only Sources At Least the 'min_mask_sep' Distance from Masked Regions Will be Considered\n",
    "mask_distance = distance_transform_edt(~permanent_mask)\n",
    "min_mask_sep = 2  \n",
    "\n",
    "# Make Copies of Mosaic and Masked Image; Save Masked Image to Output Directory\n",
    "original_mosaic = mosaic.copy()  \n",
    "masked_image = original_mosaic.copy()\n",
    "masked_image[permanent_mask] = 0\n",
    "masked_image_file = os.path.join(output_dir, \"masked_image.fits\")\n",
    "fits.PrimaryHDU(masked_image, header=mosaic_header).writeto(masked_image_file, overwrite=True)\n",
    "print(f\"Masked image saved as {masked_image_file}\")\n",
    "\n",
    "### Iterative Cycle Set Up\n",
    "\n",
    "ncycles = 4   # Number of cycles: set by user\n",
    "\n",
    "cumulative_working = mosaic.copy()\n",
    "cumulative_exclusion_mask = np.zeros_like(mosaic, dtype=bool)\n",
    "all_new_sources = []\n",
    "\n",
    "# Iterate Through All Cycles\n",
    "for cycle in range(1, ncycles+1):\n",
    "    print(f\"\\n========== Starting Iterative Cycle {cycle} ==========\")\n",
    "    detection_image = cumulative_working.copy()\n",
    "    detection_image[cumulative_exclusion_mask] = np.nan\n",
    "    \n",
    "    if cycle == 1:\n",
    "        tsig = 5.0    # threshold above background; set by user\n",
    "    else:\n",
    "        tsig = 3.0    # optional; lower threshold after first iteration\n",
    "\n",
    "    # PSF Subtraction Function\n",
    "    cumulative_working, new_sources = psf_subtraction_cycle(\n",
    "        detection_image, cumulative_working, cycle, psf_data, output_dir,\n",
    "        mosaic_header, permanent_mask, mask_distance, min_mask_sep,\n",
    "        catalog_filename, threshold_sigma=tsig)\n",
    "    all_new_sources.extend(new_sources)\n",
    "    \n",
    "    # Update Exclusion Mask; Prevents Re-Subtraction\n",
    "    box_half = 1 # set size for each source\n",
    "    for (x, y) in new_sources:\n",
    "        x_center = int(round(x))\n",
    "        y_center = int(round(y))\n",
    "        x_min_box = max(0, x_center - box_half)\n",
    "        x_max_box = min(mosaic.shape[1], x_center + box_half + 1)\n",
    "        y_min_box = max(0, y_center - box_half)\n",
    "        y_max_box = min(mosaic.shape[0], y_center + box_half + 1)\n",
    "        box = cumulative_working[y_min_box:y_max_box, x_min_box:x_max_box]\n",
    "        if np.all(np.isnan(box)):\n",
    "            continue\n",
    "        flat = box.flatten()\n",
    "        valid = np.where(~np.isnan(flat))[0]\n",
    "        if len(valid) == 0:\n",
    "            continue\n",
    "        sorted_idx = valid[np.argsort(flat[valid])[::-1]]\n",
    "        for idx in sorted_idx[:3]:\n",
    "            row = y_min_box + idx // (x_max_box - x_min_box)\n",
    "            col = x_min_box + idx % (x_max_box - x_min_box)\n",
    "            cumulative_exclusion_mask[row, col] = True\n",
    "\n",
    "# Recalculate Total Number of Subtracted Sources; Ensures No Duplicates\n",
    "unique_sources = set((round(x,1), round(y,1)) for (x, y) in all_new_sources)\n",
    "with open(catalog_filename, \"a\") as f:\n",
    "    f.write(f\"# Total unique sources: {len(unique_sources)}\\n\")\n",
    "\n",
    "print(f\"Catalog saved as {catalog_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc721cb-5a3e-41c4-83dd-876dc07f5dbf",
   "metadata": {},
   "source": [
    "The above Source Subtraction and Source Counts Code was developed by Emily McCallum as part of her Applied Mathematics Senior Thesis at Harvard College. Latest update: 27 Mar 2025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
