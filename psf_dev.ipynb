{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664ed2af-6701-42be-9624-9a247ec40d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from astropy.stats import sigma_clip\n",
    "from scipy.ndimage import label, maximum_position, shift, center_of_mass\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import maximum_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b39d7e-343e-461e-b3ce-0039feeb5b47",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3712630-79d1-414b-b9dd-bc1477bef91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to detect sources; returns list of positions of maxima of potential sources\n",
    "\n",
    "def detect_sources(image, threshold):\n",
    "    mask = (image > threshold)\n",
    "    labeled, nfeat = label(mask)\n",
    "    if nfeat < 1:\n",
    "        return []\n",
    "    positions = maximum_position(image, labels=labeled,\n",
    "                                 index=np.arange(1, nfeat+1))\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e40610-5a67-4ca9-ad00-654bc9e87bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to filter out sources that have other close sources within some number of pixels, as set by the user in variable 'min_sep'\n",
    "### Eliminates binary star pairs and other sources contaminated by nearby sources\n",
    "\n",
    "def remove_close_pairs(src_positions, min_sep=12):\n",
    "    filtered = []\n",
    "    for i, (x1, y1) in enumerate(src_positions):\n",
    "        too_close = False\n",
    "        for j, (x2, y2) in enumerate(src_positions):\n",
    "            if i != j:\n",
    "                dist = np.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "                if dist < min_sep:\n",
    "                    too_close = True\n",
    "                    break\n",
    "        if not too_close:\n",
    "            filtered.append((x1, y1))\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9305dc24-e705-4472-900d-c0ec10b16377",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to measure radial brightness profile of source cutouts; only considers data within bounds of 'max_radius' as set by user\n",
    "\n",
    "def radial_profile(stamp, center_y, center_x, max_radius=15):\n",
    "    \n",
    "    h, w = stamp.shape\n",
    "    y, x = np.indices((h, w))\n",
    "    r = np.sqrt((x - center_x)**2 + (y - center_y)**2)\n",
    "    \n",
    "    r_int = r.astype(int)\n",
    "    \n",
    "    profile = []\n",
    "    radii = np.arange(max_radius + 1)\n",
    "    \n",
    "    for rad in radii:\n",
    "        mask = (r_int == rad)\n",
    "        if not np.any(mask):\n",
    "            profile.append(0.0)\n",
    "        else:\n",
    "            vals = stamp[mask]\n",
    "            profile.append(np.mean(vals))\n",
    "    \n",
    "    return radii, np.array(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30b0fae-bd68-41e8-9299-946531a5b9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to verify that sources generally slope downward from center as expected, with no profile increase greater than the 'max_up_fraction' as set by user\n",
    "\n",
    "def is_monotonically_decreasing(profile, max_up_fraction=1.05):\n",
    "    for i in range(1, len(profile)):\n",
    "        prev_val = profile[i-1]\n",
    "        curr_val = profile[i]\n",
    "        if (curr_val > max_up_fraction * prev_val):\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d6532-f9a6-44dd-a960-7230c9645bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function that returns the minimum, nonzero background value for a source/PSF cutout\n",
    "\n",
    "def measure_min_nonzero_background_entire(cutout):\n",
    "    valid = cutout[cutout > 0]  \n",
    "    if valid.size == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.min(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2d1b8b-af25-4dfa-ba48-4a95227ca3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to mask out local companions surrounding the main star in each source; uses a threshold based on 6 times the local background average\n",
    "\n",
    "def mask_local_maxima_around_companion(stamp,\n",
    "                                       main_star=None,\n",
    "                                       background_corner_size=10,\n",
    "                                       mask_radius=3,\n",
    "                                       local_max_size=3):\n",
    "    \n",
    "    stamp_masked = stamp.copy()\n",
    "    \n",
    "    if main_star is None:\n",
    "        ypeak, xpeak = maximum_position(stamp_masked)\n",
    "        main_star = (ypeak, xpeak)\n",
    "    else:\n",
    "        ypeak, xpeak = main_star\n",
    "\n",
    "    avg_bg = measure_cutout_corners_background(stamp_masked, corner_size=background_corner_size)\n",
    "    companion_threshold = 6.0 * avg_bg\n",
    "    if companion_threshold == 0:\n",
    "        companion_threshold = 0.1\n",
    "\n",
    "    local_max = maximum_filter(stamp_masked, size=local_max_size)\n",
    "    peaks = (stamp_masked == local_max) & (stamp_masked >= companion_threshold)\n",
    "    \n",
    "    peak_coords = np.argwhere(peaks)\n",
    "    \n",
    "    h, w = stamp_masked.shape\n",
    "    yy, xx = np.indices((h, w))\n",
    "    \n",
    "    for (py, px) in peak_coords:\n",
    "        if (py, px) != (ypeak, xpeak):\n",
    "            rr = np.sqrt((xx - px)**2 + (yy - py)**2)\n",
    "            companion_area = (rr <= mask_radius)\n",
    "            stamp_masked[companion_area] = np.nan\n",
    "\n",
    "    return stamp_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e64a1-e8a7-4cf4-9fe8-071c34eb67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to calculate a median local background for a source/PSF cutout, using the data from the corners of the cutout (corner size set by user)\n",
    "\n",
    "def measure_cutout_corners_background(cutout, corner_size=10):\n",
    "    h, w = cutout.shape\n",
    "    \n",
    "    corner_tl = cutout[:corner_size, :corner_size].ravel()\n",
    "    corner_tr = cutout[:corner_size, w-corner_size:].ravel()\n",
    "    corner_bl = cutout[h-corner_size:, :corner_size].ravel()\n",
    "    corner_br = cutout[h-corner_size:, w-corner_size:].ravel()\n",
    "\n",
    "    corners = np.concatenate([corner_tl, corner_tr, corner_bl, corner_br])\n",
    "    bg = np.median(corners)\n",
    "    \n",
    "    return bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771a5c1-c479-4215-872a-cf4855c0a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to align the PSF with the position of the main star in the source cutout\n",
    "\n",
    "def shift_psf_to_star(psf, star_x, star_y, cutout_size):\n",
    "    cy = cutout_size // 2\n",
    "    cx = cutout_size // 2\n",
    "    shift_y = star_x - cy\n",
    "    shift_x = star_y - cx\n",
    "    shifted = shift(psf, (shift_y, shift_x), order=1, mode='constant', cval=0.0)\n",
    "    return shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484fda2-598f-4f05-a29d-a255aa7333ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to fit the PSF model to each source cutout using a least-squares computational approach\n",
    "### Includes a constant background offset value (currently 1.0) that can be adjusted by the user as needed\n",
    "\n",
    "def linear_amplitude_fit(cutout, star_positions, psf, delta=5.0, max_iter=10, tol=1e-6):\n",
    "    h, w = cutout.shape\n",
    "    npix = h * w \n",
    "    nstar = len(star_positions) \n",
    "    \n",
    "    data_flat = cutout.ravel() \n",
    "    \n",
    "    \n",
    "    A = np.zeros((npix, nstar+1), dtype=np.float64)\n",
    "    shifted_psfs = []\n",
    "    \n",
    "    for i, (sx, sy) in enumerate(star_positions):\n",
    "        shifted_p = shift_psf_to_star(psf, sx, sy, h)\n",
    "        shifted_psfs.append(shifted_p)\n",
    "        A[:, i] = shifted_p.ravel()\n",
    "    \n",
    "    # constant background offset for subtraction; adjust as needed\n",
    "    A[:, -1] = 1.0\n",
    "    \n",
    "    weights = np.ones(npix) \n",
    "    x_old = None\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        W_sqrt = np.sqrt(weights)\n",
    "        A_weighted = A * W_sqrt[:, np.newaxis]\n",
    "        b_weighted = data_flat * W_sqrt\n",
    "        \n",
    "        x, residuals, rank, svals = np.linalg.lstsq(A_weighted, b_weighted, rcond=None)\n",
    "\n",
    "        r = data_flat - A @ x\n",
    "        \n",
    "        new_weights = np.where(np.abs(r) <= delta, 1.0, delta / np.abs(r))\n",
    "        \n",
    "        if x_old is not None and np.linalg.norm(x - x_old) < tol:\n",
    "            break\n",
    "        x_old = x.copy()\n",
    "        weights = new_weights\n",
    "    \n",
    "    model_img = np.zeros_like(cutout, dtype=np.float64)\n",
    "    for i in range(nstar):\n",
    "        model_img += x[i] * shifted_psfs[i]\n",
    "    model_img += x[-1]\n",
    "    \n",
    "    return x, model_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc0483-82d2-4f7d-a5ac-371f5904fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to mask out the cores of companion stars within a source cutout\n",
    "### Mask radius for companions is set by the user in 'mask_radius'\n",
    "\n",
    "def companion_mask(cutout_shape, star_positions, main_star_index=0, mask_radius=4):\n",
    "    mask = np.ones(cutout_shape, dtype=bool)\n",
    "    for i, (sx, sy) in enumerate(star_positions):\n",
    "        if i == main_star_index:\n",
    "            continue \n",
    "        x_min = max(0, int(sx) - mask_radius)\n",
    "        x_max = min(cutout_shape[0], int(sx) + mask_radius+1)\n",
    "        y_min = max(0, int(sy) - mask_radius)\n",
    "        y_max = min(cutout_shape[1], int(sy) + mask_radius+1)\n",
    "        mask[x_min:x_max, y_min:y_max] = False\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b978c6-2dd0-4fa0-91a2-b4e26dd7135a",
   "metadata": {},
   "source": [
    "## Main PSF Refinement Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df682f43-9db4-49ac-bde6-6020a2fd3362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_psf_from_mosaic(mosaic_path,\n",
    "                           output_dir,\n",
    "                           cutout_size=105,\n",
    "                           num_stars=200,\n",
    "                           threshold_sigma=4.0,\n",
    "                           min_sep=5,\n",
    "                           sat_limit=80,\n",
    "                           iterations=2,\n",
    "                           alpha=0.001,\n",
    "                           sigma_clip_level=10.0,\n",
    "                           mask_radius=2,\n",
    "                           save_residuals=True):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Load Data\n",
    "    with fits.open(mosaic_path) as hdul:\n",
    "        data = hdul[0].data\n",
    "\n",
    "    # Detect and Filter Sources\n",
    "    mean_val = np.mean(data)\n",
    "    med_val = np.median(data)\n",
    "    std_val = np.std(data)\n",
    "    detect_thresh = med_val + threshold_sigma * std_val\n",
    "    \n",
    "    all_positions = detect_sources(data, detect_thresh)\n",
    "    print(f\"Detected {len(all_positions)} sources above threshold={detect_thresh:.2f}.\")\n",
    "\n",
    "    # Sort by Brightness\n",
    "    sorted_positions = sorted(all_positions,\n",
    "                              key=lambda pos: data[pos[0], pos[1]],\n",
    "                              reverse=True)\n",
    "\n",
    "    # Remove Close Pairs (Binary Pairs)\n",
    "    isolated = remove_close_pairs(sorted_positions, min_sep=min_sep)\n",
    "\n",
    "    filtered_positions = []\n",
    "    half = cutout_size // 2\n",
    "\n",
    "    for (sx, sy) in isolated:\n",
    "        if (sx - half < 0 or sx + half >= data.shape[0] or\n",
    "            sy - half < 0 or sy + half >= data.shape[1]):\n",
    "            continue\n",
    "            \n",
    "        sub = data[sx-half : sx+half+1, sy-half : sy+half+1]\n",
    "\n",
    "        cy, cx = sub.shape[0] // 2, sub.shape[1] // 2\n",
    "        yy, xx = np.indices(sub.shape)\n",
    "        rr = np.sqrt((xx - cx)**2 + (yy - cy)**2)\n",
    "        core_mask = (rr <= 10) \n",
    "\n",
    "        if np.any(sub[core_mask] == 0):\n",
    "            continue\n",
    "\n",
    "        center_val = sub[cy, cx]\n",
    "        if center_val < np.max(sub):\n",
    "            continue\n",
    "\n",
    "        com = center_of_mass(sub)\n",
    "        shift_y = half - com[0]\n",
    "        shift_x = half - com[1]\n",
    "        sub_centered = shift(sub, (shift_y, shift_x),\n",
    "                             order=1, mode='constant', cval=0.0)\n",
    "\n",
    "        # Measure Radial Profile\n",
    "        stamp = sub_centered\n",
    "        cy2, cx2 = stamp.shape[0] // 2, stamp.shape[1] // 2\n",
    "        radii, prof = radial_profile(stamp, cy2, cx2)\n",
    "    \n",
    "        if not is_monotonically_decreasing(prof, max_up_fraction=1.05):\n",
    "            continue\n",
    "\n",
    "        filtered_positions.append((sx, sy))\n",
    "\n",
    "    # Select Initial List of 'num_star' Sources\n",
    "    picked = filtered_positions[:num_stars]\n",
    "\n",
    "    half = cutout_size // 2\n",
    "    cutouts = []\n",
    "    \n",
    "    for (sx, sy) in picked:\n",
    "        if (sx-half < 0 or sx+half >= data.shape[0] or\n",
    "            sy-half < 0 or sy+half >= data.shape[1]):\n",
    "            continue\n",
    "        \n",
    "        sub = data[sx-half:sx+half+1, sy-half:sy+half+1]\n",
    "        if np.max(sub) >= sat_limit:\n",
    "            continue\n",
    "        \n",
    "        flux_sub = np.sum(sub)\n",
    "        if flux_sub <= 0:\n",
    "            continue\n",
    "        \n",
    "        # Re-center Source on Center of Mass\n",
    "        com = center_of_mass(sub)\n",
    "        shift_y = half - com[0]\n",
    "        shift_x = half - com[1]\n",
    "        sub_centered = shift(sub, (shift_y, shift_x),\n",
    "                             order=1, mode='constant', cval=0.0)\n",
    "        \n",
    "        flux_centered = np.sum(sub_centered)\n",
    "        if flux_centered <= 0:\n",
    "            continue\n",
    "        \n",
    "        stamp = sub_centered.copy()\n",
    "        cutouts.append(stamp)\n",
    "\n",
    "    print(f\"Final re-centered cutouts used: {len(cutouts)}\")\n",
    "\n",
    "    # Save Each Cutout to a Separate FITS File in Output Directory\n",
    "    for i, c in enumerate(cutouts, start=1):\n",
    "        cutout_file = os.path.join(output_dir, f\"initial_cutout_{i}.fits\")\n",
    "        fits.PrimaryHDU(c).writeto(cutout_file, overwrite=True)\n",
    "\n",
    "\n",
    "    # Begin Process to Build Initial PSF\n",
    "    if len(cutouts) == 0:\n",
    "        print(\"No valid cutouts found. Exiting.\")\n",
    "        return None\n",
    "\n",
    "    masked_cutouts = []\n",
    "    i = 0\n",
    "    for stamp in cutouts:\n",
    "\n",
    "        bg_min = measure_min_nonzero_background_entire(stamp)\n",
    "        stamp_bsub = np.clip(stamp - bg_min, 0, None) \n",
    "    \n",
    "        # Mask Companion Sources Surrounding Main Star\n",
    "        stamp_masked = mask_local_maxima_around_companion(stamp_bsub, \n",
    "                                                          main_star=None,\n",
    "                                                          background_corner_size=10,\n",
    "                                                          mask_radius=3,\n",
    "                                                          local_max_size = 3)\n",
    "                                                            \n",
    "        masked_cutouts.append(stamp_masked)\n",
    "\n",
    "        # Save Masked Cutouts to Separate FITS Files in Output Directory\n",
    "        stampmask_file = os.path.join(output_dir, f\"stampmask{i+1}.fits\")\n",
    "        fits.PrimaryHDU(stamp_masked).writeto(stampmask_file, overwrite=True)\n",
    "        i += 1\n",
    "\n",
    "    # Build Initial PSF from Masked Cutouts\n",
    "    stack = np.stack(masked_cutouts, axis=0)\n",
    "    psf_init = np.nanmedian(stack, axis=0)\n",
    "    psf_init = np.clip(psf_init, 0, None)\n",
    "\n",
    "    init_sum = np.nansum(psf_init)\n",
    "    if init_sum > 0:\n",
    "        psf_init /= init_sum\n",
    "\n",
    "    print(f\"Initial PSF => sum={psf_init.sum():.3f}, max={psf_init.max():.3f}.\")\n",
    "\n",
    "    psf_current = psf_init.copy()\n",
    "    fits.PrimaryHDU(psf_current).writeto(os.path.join(output_dir, \"psf_initial.fits\"), overwrite=True)\n",
    "\n",
    "    # PSF Residual Iterative Refinement\n",
    "    for it in range(iterations):\n",
    "        print(f\"\\n--- Iteration {it+1}/{iterations} ---\")\n",
    "        residuals = []\n",
    "        masks = []\n",
    "\n",
    "        for c_idx, stamp in enumerate(cutouts):\n",
    "\n",
    "            bg_min = measure_min_nonzero_background_entire(stamp)\n",
    "            \n",
    "            stamp_bsub = stamp - bg_min\n",
    "            \n",
    "            stamp_bsub = np.clip(stamp_bsub, 0, None)\n",
    "            \n",
    "            peak_cut = stamp_bsub.max()\n",
    "\n",
    "            if peak_cut <= 0:\n",
    "                resid = stamp_bsub.copy()\n",
    "                mask = np.ones_like(stamp, dtype=bool)\n",
    "            else:\n",
    "                # Identify Main Star\n",
    "                main_detect_thr = 0.3 * peak_cut\n",
    "                main_star_mask = (stamp_bsub > main_detect_thr)\n",
    "                lbl_main, n_main = label(main_star_mask)\n",
    "                if n_main < 1:\n",
    "                    resid = stamp_bsub.copy()\n",
    "                    mask = np.ones_like(stamp, dtype=bool)\n",
    "                else:\n",
    "                    loc_pos = maximum_position(stamp_bsub, labels=lbl_main,\n",
    "                                               index=np.arange(1, n_main+1))\n",
    "                    # Sort by Decreasing Brightness\n",
    "                    loc_pos_sorted = sorted(loc_pos,\n",
    "                                            key=lambda xy: stamp_bsub[xy[0], xy[1]],\n",
    "                                            reverse=True)\n",
    "                    main_star = loc_pos_sorted[0]\n",
    "                    #print(\"Main star detected at:\", main_star)\n",
    "        \n",
    "                    # Calculate Average Background\n",
    "                    avg_bg = measure_cutout_corners_background(stamp, corner_size=10)\n",
    "                    #print(\"Average background (from corners):\", avg_bg)\n",
    "        \n",
    "                    companion_thr = 6 * avg_bg\n",
    "                    #print(\"Companion threshold (6x avg_bg):\", companion_thr)\n",
    "        \n",
    "                    companion_binary = stamp_bsub > companion_thr\n",
    "        \n",
    "                    lbl_comp, n_comp = label(companion_binary)\n",
    "        \n",
    "                    # Build Companion Mask\n",
    "                    final_mask = np.ones_like(stamp, dtype=bool)\n",
    "                    for comp_idx in range(1, n_comp+1):\n",
    "                        region = (lbl_comp == comp_idx)\n",
    "                        if not region[main_star[0], main_star[1]]:\n",
    "                            final_mask[region] = False\n",
    "        \n",
    "        \n",
    "                    # Amplitude Fitting Process\n",
    "                    loc_pos_all = maximum_position(stamp_bsub, labels=lbl_main,\n",
    "                                                   index=np.arange(1, n_main+1))\n",
    "                    loc_pos_sorted_all = sorted(loc_pos_all,\n",
    "                                                key=lambda xy: stamp_bsub[xy[0], xy[1]],\n",
    "                                                reverse=True)\n",
    "                    # Fits Top 5 Brightest Sources (in a cutout with a significantly bright center source, this should only be this single main source)\n",
    "                    loc_pos_sorted_all = loc_pos_sorted_all[:5]\n",
    "\n",
    "                    \n",
    "                    # Linear Amplitude Fit\n",
    "                    amps, model_img = linear_amplitude_fit(stamp_bsub, loc_pos_sorted, psf_current, delta=5.0, max_iter=10, tol=1e-6)\n",
    "\n",
    "                    # Residual Subtraction\n",
    "                    resid = stamp_bsub - model_img\n",
    "\n",
    "                    # Clip Negative Values to Zero \n",
    "                    resid = np.clip(resid, 0, None)\n",
    "\n",
    "                    # Optional: Save 'stamp_bsub' and 'model_img' for First Cutout Only to Analyze\n",
    "                    #if c_idx == 0:\n",
    "                        #stamp_bsub_filename = os.path.join(output_dir, f\"stamp_bsub_iter{it+1}_cutout1.fits\")\n",
    "                        #model_img_filename = os.path.join(output_dir, f\"model_img_iter{it+1}_cutout1.fits\")\n",
    "                        #fits.PrimaryHDU(stamp_bsub).writeto(stamp_bsub_filename, overwrite=True)\n",
    "                        #fits.PrimaryHDU(model_img).writeto(model_img_filename, overwrite=True)\n",
    "\n",
    "\n",
    "                    # Mask Companion Cores\n",
    "                    mask = companion_mask(stamp.shape, loc_pos_sorted,\n",
    "                                          main_star_index=0, mask_radius=mask_radius)\n",
    "\n",
    "            residuals.append(resid)\n",
    "            masks.append(mask)\n",
    "\n",
    "            # Optional: Save the First 5 Residuals Each Iteration for Analysis\n",
    "            #if save_residuals and c_idx < 5:\n",
    "                #resid_filename = os.path.join(\n",
    "                    #output_dir, f\"residual_cutout_{c_idx+1}_iter{it+1}.fits\")\n",
    "                #fits.PrimaryHDU(resid).writeto(resid_filename, overwrite=True)\n",
    "\n",
    "        # Combine Residuals\n",
    "        res_stack = np.stack(residuals, axis=0)\n",
    "        mask_stack = np.stack(masks, axis=0)\n",
    "        masked_res = np.where(mask_stack, res_stack, np.nan)\n",
    "\n",
    "        # Median Stack Sigma-Clipped Residuals\n",
    "        clipped = sigma_clip(masked_res, sigma=sigma_clip_level,\n",
    "                             maxiters=5, axis=0)\n",
    "        median_resid = np.nanmedian(clipped, axis=0)\n",
    "        \n",
    "        # Save Median Stack for Each Iteration\n",
    "        resid_median = os.path.join(output_dir, f\"rmstack_iter{it+1}.fits\")\n",
    "        fits.PrimaryHDU(median_resid).writeto(resid_median, overwrite=True)\n",
    "\n",
    "        # Print Residual Statistics\n",
    "        finite_vals = median_resid[np.isfinite(median_resid)]\n",
    "        if len(finite_vals) > 0:\n",
    "            min_r = np.min(finite_vals)\n",
    "            max_r = np.max(finite_vals)\n",
    "            mean_r = np.mean(finite_vals)\n",
    "        else:\n",
    "            min_r = max_r = mean_r = 0.0\n",
    "        print(f\"  Residual stats: min={min_r:.4g}, max={max_r:.4g}, mean={mean_r:.4g}\")\n",
    "\n",
    "        # Perform Residual Subtraction to Obtain Updated PSF\n",
    "        new_psf = psf_current - alpha * median_resid\n",
    "\n",
    "        # Clip Negative Values to Zero\n",
    "        new_psf = np.clip(new_psf, 0, None)\n",
    "\n",
    "        # Normalize the PSF\n",
    "        psf_sum = np.sum(new_psf)\n",
    "        if psf_sum > 0:\n",
    "            new_psf /= psf_sum\n",
    "        else:\n",
    "            print(\"PSF collapsed to zero; stopping iteration.\")\n",
    "            break\n",
    "\n",
    "        print(f\"Iteration {it+1}: sum={np.sum(new_psf):.3f}, max={new_psf.max():.4f}.\")\n",
    "\n",
    "        # Save PSF Iteration to FITS File in Output Directory\n",
    "        iter_file = os.path.join(output_dir, f\"psf_iter{it+1}.fits\")\n",
    "        fits.PrimaryHDU(new_psf).writeto(iter_file, overwrite=True)\n",
    "\n",
    "        # Update the 'psf_current' Assignment with the Updated PSF\n",
    "        psf_current = new_psf.copy()\n",
    "        \n",
    "\n",
    "    # Final Trimming: Remove the 4 Outermost Rows/Columns (Resizing Leads to Artificial Zeroed Rows/Columns Around Edges)\n",
    "    psf_final_trimmed = psf_current[4:-4, 4:-4]\n",
    "    \n",
    "    # Save Final PSF to FITS File in Output Directory\n",
    "    final_file = os.path.join(output_dir, \"psf_final.fits\")\n",
    "    fits.PrimaryHDU(psf_final_trimmed).writeto(final_file, overwrite=True)\n",
    "    print(f\"\\nRefinement complete. Final PSF saved to {final_file}.\")\n",
    "    return psf_current\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f8ea09-9d3f-4900-b6ff-3af6aa1ec6c8",
   "metadata": {},
   "source": [
    "## Main Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1cb696-c0ee-4630-b1d7-1eee2d9b2318",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Define paths to mosaic file and output directory\n",
    "    mosaic_path = 'path_to_mosaic'\n",
    "    output_dir  = 'output_directory'\n",
    "\n",
    "    # Function Parameters; current values can be used as a baseline, but should be adjusted by the user based on the input data\n",
    "    \n",
    "    cutout_size     = 105     # cutout size of PSF (pixels by pixels); after trimming in function, the final size of PSF is 'cutout_size' minus 4\n",
    "    num_stars       = 200     # initial number of brightest sources to be considered for use in PSF; further refined to a smaller number later (approx. 75% of this value)\n",
    "    threshold_sigma = 4.0     # threshold sigma used in initial detection of potential sources\n",
    "    min_sep         = 5       # minimum pixel separation between sources needed to not be considered binary pairs or 'close' sources\n",
    "    sat_limit       = 80      # limit for saturated stars, in terms of pixel-valued brightness\n",
    "    iterations      = 2       # number of refinement iterations\n",
    "    alpha           = 0.001   # scales the median stacked residual to determine how much the residual subtraction influences the current PSF; higher values result in greater changes, lower values in more gradual changes\n",
    "    sigma_clip_level= 10.0    # sigma level for outliers to be excluded in the median residual stack during the iterative PSF refinement process\n",
    "    mask_radius     = 2       # radius of mask for companion sources\n",
    "\n",
    "    final_psf = refine_psf_from_mosaic(\n",
    "        mosaic_path   = mosaic_path,\n",
    "        output_dir    = output_dir,\n",
    "        cutout_size   = cutout_size,\n",
    "        num_stars     = num_stars,\n",
    "        threshold_sigma = threshold_sigma,\n",
    "        min_sep       = min_sep,\n",
    "        sat_limit     = sat_limit,\n",
    "        iterations    = iterations,\n",
    "        alpha         = alpha,\n",
    "        sigma_clip_level = sigma_clip_level,\n",
    "        mask_radius   = mask_radius,\n",
    "        save_residuals=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4c7c12-d103-4040-a469-6cb634a135c3",
   "metadata": {},
   "source": [
    "The above PSF Development and Iterative Refinement Code was developed by Emily McCallum as part of her Applied Mathematics Senior Thesis at Harvard College. Latest update: 26 Mar 2025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
